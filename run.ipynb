{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import importlib\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import data_utils\n",
    "import model_utils_train\n",
    "import model_utils_infer\n",
    "import train_utils\n",
    "import evaluation\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(model_utils_train)\n",
    "importlib.reload(model_utils_infer)\n",
    "\n",
    "\n",
    "importlib.reload(train_utils)\n",
    "importlib.reload(evaluation)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import DistilBertPreTrainedModel\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "from transformers import DistilBertConfig, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dict = {\"train1.1\": \"./data/tiny_train-v1.1.json\",\n",
    "             \"train2.0\": \"./data/tiny_train-v2.0.json\", \n",
    "             \"dev1.1\": \"./data/dev-v1.1.json\"}\n",
    "train_data_v1 = data_utils.prep_data(file_dict[\"train1.1\"])\n",
    "train_data_v2 = data_utils.prep_data(file_dict[\"train2.0\"])\n",
    "dev_data_v1 = data_utils.prep_data(file_dict[\"dev1.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with Huggingface pretrained BERT fine-tuned on SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time (6 paragraphs): 57.1 sec\n",
      "evaluation result:\n",
      " OrderedDict([('exact', 73.33333333333333), ('f1', 88.20374794287838), ('total', 45), ('HasAns_exact', 73.33333333333333), ('HasAns_f1', 88.20374794287838), ('HasAns_total', 45)])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "importlib.reload(train_utils)\n",
    "m = model_utils.PreTrainedSQuAD()\n",
    "result = train_utils.inference(train_data_v2, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with Huggingface pretrained DistillBERT fine-tuned on SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time (6 paragraphs): 0.6 sec\n",
      "exact match: 68.51851851851852, f1 score: 84.66444049777384\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.DistilBERTSQuAD()\n",
    "result = train_utils.inference(train_data_v1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time (2067 paragraphs): 112.2 sec\n",
      "exact match: 69.24314096499526, f1 score: 79.05754999708667\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.DistilBERTSQuAD()\n",
    "result = train_utils.inference(dev_data_v1, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train and run simple DistilBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model_utils_train)\n",
    "importlib.reload(train_utils)\n",
    "m = model_utils_train.SimpleDistilBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 80.5989, Val Loss: 139.0005, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 12.9786, Val Loss: 132.6728, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 12.7889, Val Loss: 132.6098, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 12.6274, Val Loss: 133.2948, Val f1 2.104, epoch time: 1.6s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 12.6685, Val Loss: 132.4457, Val f1 2.896, epoch time: 1.6s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 12.6625, Val Loss: 132.6158, Val f1 3.084, epoch time: 1.6s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 12.6776, Val Loss: 132.2205, Val f1 4.726, epoch time: 1.6s\n",
      "Epoch: 7, LR: 0.001, Train Loss: 12.6286, Val Loss: 131.6328, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 8, LR: 0.001, Train Loss: 12.6055, Val Loss: 132.5540, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 9, LR: 0.001, Train Loss: 12.5610, Val Loss: 131.8964, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 10, LR: 0.001, Train Loss: 12.7081, Val Loss: 134.0461, Val f1 0.000, epoch time: 1.5s\n",
      "Epoch: 11, LR: 0.001, Train Loss: 12.6635, Val Loss: 131.9226, Val f1 0.806, epoch time: 1.5s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(train_utils)\n",
    "result = train_utils.train(train_data=train_data_v1, \n",
    "                           val_data=train_data_v1, \n",
    "                           model=m, patience=100, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 183])\n",
      "torch.Size([16, 183])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([10, 190])\n",
      "torch.Size([10, 190])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([10, 112])\n",
      "torch.Size([10, 112])\n",
      "torch.Size([8, 2])\n",
      "torch.Size([8, 2])\n",
      "torch.Size([8, 325])\n",
      "torch.Size([8, 325])\n",
      "torch.Size([5, 2])\n",
      "torch.Size([5, 2])\n",
      "torch.Size([5, 224])\n",
      "torch.Size([5, 224])\n",
      "torch.Size([5, 2])\n",
      "torch.Size([5, 2])\n",
      "torch.Size([5, 247])\n",
      "torch.Size([5, 247])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data_v1:\n",
    "    m(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was von Braun's role in the army's rocket program during during World War II?\n",
      "technical director of the ballistic missile program\n",
      "technical director of the ballistic missile program\n",
      "technical director of the ballistic missile program\n",
      "\n",
      "What was the name of the first vehicle to reach outer space?\n",
      "the Aggregate-4\n",
      "the aggregate - 4\n",
      "the aggregate - 4\n",
      "\n",
      "During WWII, who was in charge of the German army's rocket program?\n",
      "General Dornberger\n",
      "general dornberger\n",
      "general dornberger\n",
      "\n",
      "What was the first object to enter space?\n",
      "Aggregate-4 (A-4) rocket\n",
      "aggregate - 4 ( a - 4 ) rocket\n",
      "aggregate - 4 ( a - 4 ) rocket\n",
      "\n",
      "When did the Aggregate-4 (A-4) rocket reach space?\n",
      "1942 and 1943\n",
      "1942 and 1943\n",
      "1942 and 1943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(batch)):\n",
    "    print(batch.q[i])\n",
    "    print(batch.a[i])\n",
    "    s = torch.argmax(starts[i]).item()\n",
    "    e = torch.argmax(ends[i]).item()\n",
    "    print(t.decode(inputs[\"input_ids\"][i, s:e+1]))\n",
    "    print(t.convert_tokens_to_string(t.convert_ids_to_tokens(inputs[\"input_ids\"][i, s:e+1])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_logits, end_logits = _[:, 0], _[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0338, -0.1953,  0.3170,  0.1470,  0.3645,  0.2151,  0.4525,  0.0216,\n",
       "         0.1056,  0.0023,  0.5347,  0.3591,  0.1755,  0.0509, -0.1648, -0.1314,\n",
       "        -0.0548,  0.5700,  0.3085,  0.2198,  0.2443,  0.2767, -0.0936,  0.4682,\n",
       "        -0.2643,  0.1275, -0.4731, -0.3886, -0.3462, -0.0608,  0.0363, -0.1420,\n",
       "         0.1483, -0.3176, -0.2976, -0.2344, -0.3339, -0.2073, -0.1009,  0.0186,\n",
       "        -0.2375,  0.2723,  0.1106,  0.3088,  0.3516,  0.0856,  0.2452,  0.0366,\n",
       "        -0.0228, -0.1730,  0.1252,  0.0356,  0.0581,  0.1838,  0.0967, -0.3358,\n",
       "         0.1892, -0.7193, -0.3923, -0.1567, -0.1160, -0.2515, -0.2789, -0.2837,\n",
       "        -0.0509,  0.0798, -0.0807,  0.2901,  0.1099,  0.0578,  0.2417,  0.1205,\n",
       "         0.2458,  0.2456,  0.3944, -0.3274, -0.0044, -0.2566,  0.0513,  0.1809,\n",
       "        -0.1168, -0.2245,  0.0556, -0.0087,  0.2180,  0.0539,  0.1345, -0.0422,\n",
       "        -0.1499,  0.0030,  0.1015, -0.1616, -0.0196, -0.0209, -0.0829, -0.1064,\n",
       "         0.0142, -0.1297,  0.0788,  0.3940, -0.0192, -0.1925, -0.2047,  0.0825,\n",
       "         0.1065,  0.0166,  0.4773,  0.3917, -0.1644,  0.2218,  0.2280,  0.1743,\n",
       "         0.2586, -0.1476,  0.0344, -0.0738, -0.1323,  0.3616,  0.2285,  0.1970,\n",
       "         0.2565,  0.2100,  0.1960,  0.1211,  0.4127, -0.1219,  0.1357,  0.3980,\n",
       "         0.2559,  0.4972,  0.2744,  0.1010,  0.0125, -0.1051,  0.1108,  0.0589,\n",
       "         0.0653,  0.0397, -0.1698,  0.2475,  0.2543,  0.0270,  0.1042,  0.1358,\n",
       "         0.0374, -0.1309,  0.0399, -0.0410,  0.0554, -0.1265,  0.4634,  0.0763,\n",
       "         0.0497, -0.2292,  0.1553,  0.0149, -0.0762, -0.1041,  0.2456,  0.0790,\n",
       "         0.2776,  0.2459,  0.2727,  0.2021,  0.5145,  0.2796,  0.1173,  0.2556,\n",
       "         0.0129,  0.1826,  0.1943, -0.0259, -0.1500,  0.3212, -0.1198,  0.1410,\n",
       "        -0.1662, -0.1281,  0.1273,  0.1271, -0.1030,  0.0603,  0.0901],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 183, 768])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 183])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.prepare_data(batch)[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleDistilBERT(\n",
       "  (model): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 6th and 4th centuri'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.context[440: 460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4th'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.decode(inputs[\"input_ids\"][13, 103:104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the 6th and 4th centuries bce. [ note 1'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.decode(inputs[\"input_ids\"][13, 100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.a_index[13]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
